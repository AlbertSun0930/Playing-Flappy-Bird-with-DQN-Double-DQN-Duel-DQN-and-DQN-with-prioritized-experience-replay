# Playing Flappy Bird with DQN, Double DQN, Duel DQN, and DQN with prioritized experience replay
In this project we adopt the original DQN code from [cite](https://github.com/hardlyrichie/pytorch-flappy-bird). We use cuda to achieve much faster convergence.   We also implement 4 algorithms combined with DQN by ourselves, i.e, double-DQN, prioritized experience replay, dueling network architecture and integration of them.  
![image](https://github.com/AlbertSun0930/Playing-Flappy-Bird-with-DQN-Double-DQN-Duel-DQN-and-DQN-with-prioritized-experience-replay/blob/main/duration/GIF%202023-5-2%2017-13-46.gif)
